name: Sentinel

on:
  push:
    branches:
      - master
  pull_request:

jobs:
  install-checks:
    runs-on: ubuntu-latest
    steps:
      - name: Check HBase 2.2.7 availability
        run: |
          wget --spider https://archive.apache.org/dist/hbase/2.2.7/hbase-2.2.7-bin.tar.gz
      - name: Check Kafka 2.8.1 availability
        run: |
          wget --spider https://www.apache.org/dist/kafka/2.8.1/kafka_2.12-2.8.1.tgz
      - name: Check Spark 2.4.7 availability
        run: |
          wget --spider http://archive.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz
  test-suite:
    needs: install-checks
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.7]
        spark-version: [2.4.7]
    env:
      SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install add-ons
      run: |
        sudo apt-get install axel
    - name: Set up env [1/2]
      run: |
        echo "FINK_HOME=$GITHUB_WORKSPACE" >> $GITHUB_ENV
    - name: Install Java 8
      run: |
        source conf/java8_for_xenial.sh
        echo "JAVA_HOME=$JAVA_HOME" >> $GITHUB_ENV
    - name: Install HBase 2.2.7
      run: |
        source conf/install_hbase.sh
    - name: Install Kafka 2.6.1
      run: |
        source conf/install_kafka.sh
        echo "KAFKA_HOME=$FINK_HOME/kafka" >> $GITHUB_ENV
    - name: Install Spark 2.4.7
      run: |
        axel -n10 --quiet https://archive.apache.org/dist/spark/spark-${{ matrix.spark-version }}/spark-${{ matrix.spark-version }}-bin-hadoop2.7.tgz
        tar -xf spark-${{ matrix.spark-version }}-bin-hadoop2.7.tgz
        echo "SPARK_HOME=$FINK_HOME/spark-${{ matrix.spark-version }}-bin-hadoop2.7" >> $GITHUB_ENV
    - name: Download test data
      run: |
        cd datasim
        source download_ztf_alert_data.sh
        cd ..
        echo "FINK_ALERT_SIMULATOR=${FINK_HOME}/fink-alert-simulator" >> $GITHUB_ENV
    - name: Download simulator
      run: |
        git clone https://github.com/astrolabsoftware/fink-alert-simulator.git
    - name: Set up env [2/2]
      run: |
        echo "SPARKLIB=${SPARK_HOME}/python:${SPARK_HOME}/python/lib/py4j-0.10.7-src.zip" >> $GITHUB_ENV
        echo "$HOME/.local/bin:${FINK_HOME}/bin" >> $GITHUB_PATH
        echo "${SPARK_HOME}/bin:${SPARK_HOME}/sbin" >> $GITHUB_PATH
        echo "$FINK_ALERT_SIMULATOR/bin" >> $GITHUB_PATH
        echo "spark.yarn.jars=${SPARK_HOME}/jars/*.jar" > ${SPARK_HOME}/conf/spark-defaults.conf
        echo "ARROW_PRE_0_15_IPC_FORMAT=1" > ${SPARK_HOME}/conf/spark-env.sh
    - name: Install Python dependencies
      run: |
        pip install --upgrade pip setuptools wheel
        source ./install_python_deps.sh
        echo "PYTHONPATH="${SPARKLIB}:${FINK_HOME}:${FINK_ALERT_SIMULATOR}"" >> $GITHUB_ENV
    - name: Check env
      run: |
        echo "FINK_HOME: $FINK_HOME"
        echo "SPARK_HOME: $SPARK_HOME"
        echo "SPARKLIB: $SPARKLIB"
        echo "FINK_ALERT_SIMULATOR: $FINK_ALERT_SIMULATOR"
        echo "KAFKA_HOME: $KAFKA_HOME"
        echo "PYTHONPATH: $PYTHONPATH"
        echo "JAVA_HOME: $JAVA_HOME"
        echo `python -V`
    - name: Run test suites
      run: |
        git fetch --unshallow --quiet
        fink init -c ${FINK_HOME}/conf/fink.conf.travis
        fink_kafka start
        fink_kafka --create-topic fink_outstream
        fink_simulator --docker -c ${FINK_HOME}/conf/fink_alert_simulator.conf
        fink_test
        bash <(curl -s https://codecov.io/bash)
    - uses: act10ns/slack@v1
      with:
        status: ${{ job.status }}
      if: always()
