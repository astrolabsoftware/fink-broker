#!/bin/bash
# Copyright 2019 AstroLab Software
# Author: Julien Peloton
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
## Script to launch the python test suite and measure the coverage.
## Must be launched as fink_test
set -e
message_help="""
Run the test suite of Fink\n\n
Usage:\n
    \tfink_test [--without-integration] [-h]\n\n

By default, both unit tests and integration tests will be run.\n
You can disable the integration tests by specifying --without-integration.\n
Use -h to display this help.
"""

# Grab the command line arguments
NO_INTEGRATION=false
while [ "$#" -gt 0 ]; do
  case "$1" in
    --without-integration)
        NO_INTEGRATION=true
        shift 1
        ;;
    -h)
        echo -e $message_help
        exit
        ;;
  esac
done

# Source configuration file for tests
source $FINK_HOME/conf/fink.conf.travis
export FINK_PACKAGES=$FINK_PACKAGES
export KAFKA_IPPORT_SIM=$KAFKA_IPPORT_SIM
export KAFKA_TOPIC_SIM=$KAFKA_TOPIC_SIM
echo "Reading test configuration from $FINK_HOME/conf/fink.conf.travis"

# Add coverage_daemon to the pythonpath. See python/fink_broker/tester.py
export PYTHONPATH="${SPARK_HOME}/python/test_coverage:$PYTHONPATH"
export COVERAGE_PROCESS_START="${FINK_HOME}/.coveragerc"

# Launch the simulator - kafka & zookeeper
is_docker=`which docker-compose`
if [[ -f $is_docker ]]; then
  KAFKA_PORT_SIM=${KAFKA_PORT_SIM} docker-compose -p kafkanet -f ${FINK_HOME}/docker/docker-compose-kafka.yml up -d
else
  echo "docker-compose not found"
  echo "integration tests cannot be performed"
  exit
fi

# Launch a stream from the simulator to be used by tests
coverage run --source=${FINK_HOME} \
    --rcfile ${FINK_HOME}/.coveragerc \
    ${FINK_HOME}/bin/simulate_stream.py \
      -servers ${KAFKA_IPPORT_SIM} -topic ${KAFKA_TOPIC_SIM} -datapath ${FINK_DATA_SIM} \
      -tinterval_kafka ${TIME_INTERVAL} -poolsize ${POOLSIZE}

# Build the raw database
fink start archive --exit_after 30 --simulator -c conf/fink.conf.travis

# Run the test suite on the modules
for i in ${FINK_HOME}/python/fink_broker/*.py
do
  coverage run \
    --source=${FINK_HOME} \
    --rcfile ${FINK_HOME}/.coveragerc $i
done

# Integration tests
if [[ "$NO_INTEGRATION" = false ]] ; then
  fink start dashboard -c conf/fink.conf.travis
  fink start monitor --exit_after 30 --simulator -c conf/fink.conf.travis
  fink start classify --exit_after 30 --simulator -c conf/fink.conf.travis
  fink start filter --exit_after 30 --simulator -c conf/fink.conf.travis
fi

# Combine individual reports in one
coverage combine

unset COVERAGE_PROCESS_START
unset FINK_PACKAGES
unset KAFKA_IPPORT_SIM
unset KAFKA_TOPIC_SIM

coverage report
coverage html
